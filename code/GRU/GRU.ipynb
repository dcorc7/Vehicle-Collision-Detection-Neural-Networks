{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd14231",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd2dcf19",
   "metadata": {},
   "source": [
    "# Extract Feature from Each Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe479c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adede2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "\n",
    "# extract features from the CSV file\n",
    "def extract_frame_features(frame_df, scaler=None):\n",
    "    num_objects = len(frame_df)\n",
    "    avg_conf = frame_df[\"confidence\"].mean()\n",
    "    avg_box_area = ((frame_df[\"x_max\"] - frame_df[\"x_min\"]) *\n",
    "                    (frame_df[\"y_max\"] - frame_df[\"y_min\"])).mean()\n",
    "\n",
    "    desired_size = 13\n",
    "    class_counts = np.zeros(desired_size)\n",
    "\n",
    "    for cls in frame_df[\"object_class\"]:\n",
    "        cls = int(cls)\n",
    "        if cls < desired_size:\n",
    "            class_counts[cls] += 1\n",
    "\n",
    "    raw_features = [num_objects, avg_conf, avg_box_area] + class_counts.tolist()\n",
    "    \n",
    "    if scaler:\n",
    "        raw_features = scaler.transform([raw_features])[0]  # normalize\n",
    "    return torch.tensor(raw_features, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Process the CSV file and extract features for each frame\n",
    "def process_video_csv(csv_path, scaler = None):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    sequences = []\n",
    "    if \"frame\" not in df.columns or df.empty:\n",
    "        return torch.empty(0, 16)  # return empty tensor with correct shape\n",
    "\n",
    "    for _, frame_df in df.groupby(\"frame\"):\n",
    "        frame_feat = extract_frame_features(frame_df, scaler = scaler)\n",
    "        sequences.append(frame_feat)\n",
    "\n",
    "    if not sequences:\n",
    "        return torch.empty(0, 16)  \n",
    "    return torch.stack(sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba72817",
   "metadata": {},
   "source": [
    "# Load Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab8d73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load label CSV into a dictionary\n",
    "label_dict = {}\n",
    "with open(\"../../data/train_labels.csv\", newline = \"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        label_dict[row[\"id\"]] = int(row[\"target\"])\n",
    "\n",
    "# Gather all video directories\n",
    "video_dirs = sorted([\n",
    "    os.path.join(\"../../data/yolo_processed_data\", d)\n",
    "    for d in os.listdir(\"../../data/yolo_processed_data\")\n",
    "    if os.path.isdir(os.path.join(\"../../data/yolo_processed_data\", d))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d2ccc",
   "metadata": {},
   "source": [
    "# Split Data into Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c3a76ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out videos with >75% empty frames\n",
    "def filter_videos_by_frame_coverage(video_dirs, empty_threshold=0.75):\n",
    "    filtered = []\n",
    "    for video_dir in video_dirs:\n",
    "        csv_path = os.path.join(video_dir, \"detections.csv\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Count total frames via image files\n",
    "        jpgs = [f for f in os.listdir(video_dir) if f.lower().endswith(\".jpg\")]\n",
    "        total_frames = len(jpgs)\n",
    "        detected_frames = df[\"frame\"].nunique()\n",
    "        empty_ratio = (total_frames - detected_frames) / total_frames if total_frames > 0 else 1.0\n",
    "        if empty_ratio <= empty_threshold:\n",
    "            filtered.append(video_dir)\n",
    "    return filtered\n",
    "\n",
    "video_dirs = filter_videos_by_frame_coverage(video_dirs, empty_threshold=0.75)\n",
    "\n",
    "# Split video IDs\n",
    "video_ids = [os.path.basename(v).replace(\"video_\", \"\") for v in video_dirs]\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, temp_ids = train_test_split(video_ids, test_size=0.2, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "def get_dirs(ids):\n",
    "    return [os.path.join(\"../../data/yolo_processed_data\", \"video_\" + vid) for vid in ids]\n",
    "\n",
    "train_videos = get_dirs(train_ids)\n",
    "val_videos   = get_dirs(val_ids)\n",
    "test_videos  = get_dirs(test_ids)\n",
    "\n",
    "# Feature scaler\n",
    "feature_scaler = StandardScaler()\n",
    "all_train_feats = []\n",
    "for video_dir in train_videos:\n",
    "    df = pd.read_csv(os.path.join(video_dir, \"detections.csv\"))\n",
    "    for _, frame_df in df.groupby(\"frame\"):\n",
    "        # extract raw features (no scaler)\n",
    "        num_objects = len(frame_df)\n",
    "        avg_conf = frame_df[\"confidence\"].mean()\n",
    "        avg_box_area = ((frame_df[\"x_max\"]-frame_df[\"x_min\"])*(frame_df[\"y_max\"]-frame_df[\"y_min\"])).mean()\n",
    "        counts = np.zeros(13)\n",
    "        for cls in frame_df[\"object_class\"]:\n",
    "            c = int(cls)\n",
    "            if c < 13: counts[c] +=1\n",
    "        feat = [num_objects, avg_conf, avg_box_area] + counts.tolist()\n",
    "        all_train_feats.append(feat)\n",
    "feature_scaler.fit(all_train_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7d70a",
   "metadata": {},
   "source": [
    "# Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "277854cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Dataset class\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_dirs, label_dict, scaler=None):\n",
    "        self.video_dirs = video_dirs\n",
    "        self.label_dict = label_dict\n",
    "        self.scaler = scaler\n",
    "    def __len__(self): return len(self.video_dirs)\n",
    "    def __getitem__(self, idx):\n",
    "        video_dir = self.video_dirs[idx]\n",
    "        vid = os.path.basename(video_dir).replace(\"video_\", \"\").zfill(5)\n",
    "        label = self.label_dict.get(vid, 0)\n",
    "        df = pd.read_csv(os.path.join(video_dir, \"detections.csv\"))\n",
    "        seq = []\n",
    "        for _, frame_df in df.groupby(\"frame\"):\n",
    "            # raw features\n",
    "            num_objects = len(frame_df)\n",
    "            avg_conf = frame_df[\"confidence\"].mean()\n",
    "            avg_box_area = ((frame_df[\"x_max\"]-frame_df[\"x_min\"])*(frame_df[\"y_max\"]-frame_df[\"y_min\"])).mean()\n",
    "            counts = np.zeros(13)\n",
    "            for cls in frame_df[\"object_class\"]:\n",
    "                c = int(cls)\n",
    "                if c < 13: counts[c] +=1\n",
    "            feat = [num_objects, avg_conf, avg_box_area] + counts.tolist()\n",
    "            if self.scaler:\n",
    "                feat = self.scaler.transform([feat])[0]\n",
    "            seq.append(torch.tensor(feat, dtype=torch.float32))\n",
    "        if not seq:\n",
    "            return torch.empty(0,16), torch.tensor(label, dtype=torch.float32)\n",
    "        return torch.stack(seq), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Collate fn \n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [(x,y) for x,y in batch if x.size(0)>0]\n",
    "    if not batch: return None\n",
    "    batch.sort(key=lambda x: x[0].size(0), reverse=True)\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([s.size(0) for s in seqs])\n",
    "    padded = pad_sequence(seqs, batch_first=True)\n",
    "    return padded, lengths, torch.stack(labels)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(VideoDataset(train_videos, label_dict, feature_scaler), batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(VideoDataset(val_videos,   label_dict, feature_scaler), batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(VideoDataset(test_videos,  label_dict, feature_scaler), batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c74f3",
   "metadata": {},
   "source": [
    "# Define the GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d75eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model for classification\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, num_layers):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first = True, bidirectional = True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, hn = self.gru(packed)  \n",
    "        out = self.fc(hn[-1])     # Get last hidden state\n",
    "        return self.sigmoid(out).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179444f0",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d26310c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, patience, device, epochs, print_epochs=False):\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            x_batch, lengths, y_batch = batch\n",
    "            x_batch, lengths, y_batch = x_batch.to(device), lengths.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch, lengths)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                if batch is None:\n",
    "                    continue\n",
    "\n",
    "                x_batch, lengths, y_batch = batch\n",
    "                x_batch, lengths, y_batch = x_batch.to(device), lengths.to(device), y_batch.to(device)\n",
    "\n",
    "                outputs = model(x_batch, lengths)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                all_preds.extend(outputs.cpu().numpy())\n",
    "                all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Print info\n",
    "        if print_epochs:\n",
    "            print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                if print_epochs:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "147e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to iterate through different combinations of hyperparameters for GRU\n",
    "def tune_gru_hyperparameters(train_loader, val_loader, params, input_size, epochs=50, patience=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_params = None\n",
    "    all_results = []\n",
    "\n",
    "    best_train_losses = []\n",
    "    best_val_losses = []\n",
    "\n",
    "    for hidden_size in params[\"hidden_size\"]:\n",
    "        for dropout in params[\"dropout\"]:\n",
    "            for learning_rate in params[\"learning_rate\"]:\n",
    "                for num_layers in params[\"num_layers\"]:\n",
    "                    for weight_decay in params.get('weight_decay', [0.0]):\n",
    "                        for optimizer_type in params.get(\"optimizer\", [\"adam\"]):\n",
    "                            print(f\"Training with hidden_size={hidden_size}, dropout={dropout}, \"\n",
    "                                f\"lr={learning_rate}, num_layers={num_layers}, optimizer={optimizer_type}\")\n",
    "\n",
    "                            model = GRUClassifier(input_dim=input_size,\n",
    "                                                hidden_dim=hidden_size,\n",
    "                                                num_layers=num_layers,\n",
    "                                                dropout=dropout)\n",
    "\n",
    "                            if optimizer_type.lower() == \"adam\":\n",
    "                                optimizer = torch.optim.Adam(\n",
    "                                    model.parameters(),\n",
    "                                    lr=learning_rate,\n",
    "                                    weight_decay=weight_decay\n",
    "                                )\n",
    "                            else:\n",
    "                                optimizer = torch.optim.SGD(\n",
    "                                    model.parameters(),\n",
    "                                    lr=learning_rate,\n",
    "                                    weight_decay=weight_decay\n",
    "                                )\n",
    "\n",
    "                            criterion = nn.BCELoss()\n",
    "\n",
    "                            train_losses, val_losses = train_model(\n",
    "                                model=model,\n",
    "                                train_loader=train_loader,\n",
    "                                val_loader=val_loader,\n",
    "                                criterion=criterion,\n",
    "                                optimizer=optimizer,\n",
    "                                patience=patience,\n",
    "                                device=device,\n",
    "                                epochs=epochs,\n",
    "                                print_epochs=True\n",
    "                            )\n",
    "\n",
    "                            final_val_loss = val_losses[-1]\n",
    "                            all_results.append({\n",
    "                                \"hidden_size\": hidden_size,\n",
    "                                \"dropout\": dropout,\n",
    "                                \"learning_rate\": learning_rate,\n",
    "                                \"num_layers\": num_layers,\n",
    "                                \"optimizer\": optimizer_type,\n",
    "                                \"final_val_loss\": final_val_loss\n",
    "                            })\n",
    "\n",
    "                            # Save best model and losses\n",
    "                            if final_val_loss < best_val_loss:\n",
    "                                best_val_loss = final_val_loss\n",
    "                                best_params = {\n",
    "                                    \"hidden_size\": hidden_size,\n",
    "                                    \"dropout\": dropout,\n",
    "                                    \"learning_rate\": learning_rate,\n",
    "                                    \"num_layers\": num_layers,\n",
    "                                    \"optimizer\": optimizer_type\n",
    "                                }\n",
    "                                best_train_losses = train_losses\n",
    "                                best_val_losses = val_losses\n",
    "\n",
    "    return best_params, all_results, best_train_losses, best_val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0457103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden_size=128, dropout=0.0, lr=0.001, num_layers=2, optimizer=adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MyNewEnv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"hidden_size\": [128],\n",
    "    \"num_layers\": [2],\n",
    "    \"dropout\": [0.0, 0.1, 0.2],\n",
    "    \"learning_rate\": [0.001, 0.0001, 0.00001],\n",
    "    \"weight_decay\": [0.001],\n",
    "    \"optimizer_type\": [\"adam\"]  \n",
    "}\n",
    "\n",
    "\n",
    "input_size = 16  # 3 summary features + 10 class counts + 3 one-hot encodings \n",
    "epochs = 50\n",
    "patience = 10\n",
    "\n",
    "best_params, results, train_losses, val_losses = tune_gru_hyperparameters(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    params=params,\n",
    "    input_size=input_size,\n",
    "    epochs=50,\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.title(\"Training vs Validation Loss per Epoch (Best Model)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MyNewEnv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6890, Val Loss: 0.6789\n",
      "Epoch 2, Train Loss: 0.6764, Val Loss: 0.6604\n",
      "Epoch 3, Train Loss: 0.6577, Val Loss: 0.6509\n",
      "Epoch 4, Train Loss: 0.6534, Val Loss: 0.6319\n",
      "Epoch 5, Train Loss: 0.6458, Val Loss: 0.6247\n",
      "Epoch 6, Train Loss: 0.6450, Val Loss: 0.6449\n",
      "Epoch 7, Train Loss: 0.6336, Val Loss: 0.6810\n",
      "Epoch 8, Train Loss: 0.6279, Val Loss: 0.6580\n",
      "Epoch 9, Train Loss: 0.5879, Val Loss: 0.6660\n",
      "Epoch 10, Train Loss: 0.5370, Val Loss: 0.6899\n",
      "Epoch 11, Train Loss: 0.4811, Val Loss: 0.7455\n",
      "Epoch 12, Train Loss: 0.4528, Val Loss: 0.7743\n",
      "Epoch 13, Train Loss: 0.4019, Val Loss: 0.8110\n",
      "Epoch 14, Train Loss: 0.3282, Val Loss: 0.8802\n",
      "Epoch 15, Train Loss: 0.2797, Val Loss: 0.9395\n",
      "Early stopping triggered\n",
      "Final Results:\n",
      "Training Loss: 0.2797, Validation Loss: 0.9395, Test Loss: 1.0242, Test Accuracy: 0.5586\n",
      "Precision: 0.6000, Recall: 0.5696, F1-score: 0.5844\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Initialize model with best params\n",
    "best_model = GRUClassifier(\n",
    "    input_dim=input_size,\n",
    "    hidden_dim=best_params[\"hidden_size\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dropout=best_params[\"dropout\"]\n",
    ").to(device)\n",
    "\n",
    "# Retrain on train/val set using best hyperparameters\n",
    "optimizer = torch.optim.Adam(\n",
    "    best_model.parameters(),\n",
    "    lr=best_params[\"learning_rate\"],\n",
    "    weight_decay=best_params.get(\"weight_decay\", 0.0)  # defaults to 0 if missing\n",
    ")\n",
    "\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    patience=10,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    print_epochs=True\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        x_batch, lengths, y_batch = batch\n",
    "        x_batch, lengths, y_batch = x_batch.to(device), lengths.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = best_model(x_batch, lengths)\n",
    "        if outputs.dim() == 0:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print('Final Results:')\n",
    "print(f'Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}, '\n",
    "      f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels = [0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Collision\", \"Collision\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdfcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyNewEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
